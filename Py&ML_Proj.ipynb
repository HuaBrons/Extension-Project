{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter, ExcelFile, read_excel, DataFrame\n",
    "from openpyxl import load_workbook\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcelSheet1(excelfile):\n",
    "    return (read_excel(excelfile)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcelRange(excelfile,sheetname=\"Sheet1\",startrow=1,endrow=1,startcol=1,endcol=1):\n",
    "    values=(read_excel(excelfile, sheetname,header=None)).values;\n",
    "    return values[startrow-1:endrow,startcol-1:endcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcel(excelfile,**args):\n",
    "    if args:\n",
    "        data=readExcelRange(excelfile,**args)\n",
    "    else:\n",
    "        data=readExcelSheet1(excelfile)\n",
    "    [nr,nc]=data.shape\n",
    "    if [nr,nc]==[1,1]:\n",
    "        return data[0,0]\n",
    "    elif min([nr,nc])==1:\n",
    "        return np.squeeze(data)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeExcelData(x,excelfile,sheetname,startrow,startcol):\n",
    "    df=DataFrame(x)\n",
    "    book = load_workbook(excelfile)\n",
    "    writer = ExcelWriter(excelfile, engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    df.to_excel(writer, sheet_name=sheetname,startrow=startrow-1, startcol=startcol-1, header=False, index=False)\n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSheetNames(excelfile):\n",
    "    return (ExcelFile(excelfile)).sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelfile_train = r'/Users/heart/Desktop/learning/Py&ML/project/fashion-mnist_train.csv'\n",
    "excelfile_test = r'/Users/heart/Desktop/learning/Py&ML/project/fashion-mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.read_csv(excelfile_train).values\n",
    "Xtest = pd.read_csv(excelfile_test).values\n",
    "\n",
    "Ytrain = Xtrain[:,0]\n",
    "Ytest = Xtest[:,0]\n",
    "Xtrain = Xtrain[:,1:]\n",
    "Xtest = Xtest[:,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Histogram and Bayesian using PCA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  7, 14, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Xtrain[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = np.mean(Xtrain,axis=0)\n",
    "Z = Xtrain - μ\n",
    "C = np.dot(Z.T,Z)/(len(μ)-1)\n",
    "[λ,V] = LA.eigh(C)\n",
    "λ = np.flipud(λ)\n",
    "V = np.flipud(V.T)\n",
    "P = np.dot(Z,V.T)\n",
    "\n",
    "v1 = V[0,:]\n",
    "v2 = V[1,:]\n",
    "PC = P[:,0:2]\n",
    "RP_aprox = np.dot(PC,V[0:2,:])\n",
    "X_aprox = RP_aprox + μ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4673902181151126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(λ[0]+λ[1])/sum(λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC: contain the PC1 & PC2\n",
    "\n",
    "range_PC1 = [np.min(PC[:,0]), np.max(PC[:,0])]\n",
    "range_PC2 = [np.min(PC[:,1]), np.max(PC[:,1])]\n",
    "\n",
    "B = 32\n",
    "\n",
    "def Build_2DHistogramClassifier(B,PC,Ytrain,Xtrain,range_PC1,range_PC2):\n",
    "    Hlabel = np.zeros([10,B,B]).astype('int32')\n",
    "    PC1_bins = np.round((B-1)*(PC[:,0].astype(float)-range_PC1[0])/(range_PC1[1]-range_PC1[0])).astype('int32')\n",
    "    PC2_bins = np.round((B-1)*(PC[:,1].astype(float)-range_PC2[0])/(range_PC2[1]-range_PC2[0])).astype('int32')\n",
    "    for i in range(Xtrain.shape[0]):\n",
    "        Hlabel[Ytrain[i],PC1_bins[i],PC2_bins[i]] += 1\n",
    "    return Hlabel\n",
    "Hlabel = Build_2DHistogramClassifier(B,PC,Ytrain,Xtrain,range_PC1,range_PC2)\n",
    "\n",
    "###############\n",
    "\n",
    "Mulabel = np.array([np.mean(PC[np.argwhere(Ytrain == x)[:,0],:],axis=0) for x in np.unique(Ytrain)])\n",
    "Covlabel = np.array([np.cov(PC[np.argwhere(Ytrain == x)[:,0],:].T.astype(float)) for x in np.unique(Ytrain)])\n",
    "\n",
    "def Gauss_2d_pdf(x,mu,sigma):\n",
    "    d = np.shape(sigma)[0]\n",
    "    exp_item = np.exp(-np.dot(np.dot(np.asarray(x-mu),np.linalg.inv(sigma)),np.asarray(x-mu).T)/2)\n",
    "    return exp_item /((2*np.pi)**(d/2) *np.sqrt(np.abs(np.linalg.det(sigma))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ztrain = Xtrain- μ\n",
    "Ptrain = np.dot(Ztrain,np.array([v1,v2]).T)\n",
    "Rtrain = np.dot(Ptrain,np.array([v1,v2]))\n",
    "Xtrainrec = Rtrain + μ\n",
    "\n",
    "\n",
    "pc1_trainbin_loc = np.round((B-1)*(Ptrain[:,0].astype(float)-range_PC1[0])/(range_PC1[1]-range_PC1[0])).astype('int32')\n",
    "pc2_trainbin_loc = np.round((B-1)*(Ptrain[:,1].astype(float)-range_PC2[0])/(range_PC2[1]-range_PC2[0])).astype('int32')\n",
    "\n",
    "Histogram_Label = np.zeros([10,Xtrain.shape[0]]).astype('int32')\n",
    "Histogram_denominator = np.zeros(Xtrain.shape[0]).astype('int32')\n",
    "for i in range(10):\n",
    "    Histogram_Label[i,:] = Hlabel[i,pc1_trainbin_loc,pc2_trainbin_loc]\n",
    "    Histogram_denominator += Histogram_Label[i,:]\n",
    "    \n",
    "Histogram_classifier = np.zeros([10,Xtrain.shape[0]])\n",
    "for i in range(10):\n",
    "    Histogram_classifier[i,:] = Histogram_Label[i,:]/Histogram_denominator\n",
    "    Histogram_classifier[i,np.argwhere(np.isnan(Histogram_classifier[i,:]))] = 0\n",
    "\n",
    "Digits = [x for x in range(10)]\n",
    "DH = np.zeros(Xtrain.shape[0]).astype('int32')\n",
    "PH = np.zeros(Xtrain.shape[0])\n",
    "for j in range(Xtrain.shape[0]):\n",
    "    DH[j] = Digits[np.argmax(Histogram_classifier[:,j])]\n",
    "    PH[j] = np.max(Histogram_classifier[:,j])\n",
    "    \n",
    "\n",
    "\n",
    "Bayesian_Label = np.zeros([10,Xtrain.shape[0]])\n",
    "Bayesian_denominator = np.zeros(Xtrain.shape[0])\n",
    "for i in range(10):\n",
    "    Bayesian_Label[i,:] = np.array([Gauss_2d_pdf(x,Mulabel[i],Covlabel[i]) for x in Ptrain])\n",
    "    Bayesian_denominator += Bayesian_Label[i,:]\n",
    "    \n",
    "Bayesian_classifier = np.zeros([10,Xtrain.shape[0]])\n",
    "for i in range(10):\n",
    "    Bayesian_classifier[i,:] = Bayesian_Label[i,:]/Bayesian_denominator\n",
    "    Bayesian_classifier[i,np.argwhere(np.isnan(Bayesian_classifier[i,:]))] = 0\n",
    "\n",
    "Digits = [x for x in range(10)]\n",
    "DB = np.zeros(Xtrain.shape[0]).astype('int32')\n",
    "PB = np.zeros(Xtrain.shape[0])\n",
    "for j in range(Xtrain.shape[0]):\n",
    "    DB[j] = Digits[np.argmax(Bayesian_classifier[:,j])]\n",
    "    PB[j] = np.max(Bayesian_classifier[:,j])\n",
    "\n",
    "TrainAccurancy_H = 0.\n",
    "TrainAccurancy_B = 0.\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    TrainAccurancy_H += np.sum(Ytrain[i] == DH[i])/Xtrain.shape[0]\n",
    "    TrainAccurancy_B += np.sum(Ytrain[i] == DB[i])/Xtrain.shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5669833333332758\n",
      "0.5226833333332807\n"
     ]
    }
   ],
   "source": [
    "print(TrainAccurancy_H)\n",
    "print(TrainAccurancy_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "Ztest = Xtest - μ\n",
    "Ptest = np.dot(Ztest,np.array([v1,v2]).T)\n",
    "Rtest = np.dot(Ptest,np.array([v1,v2]))\n",
    "Xtestrec = Rtest + μ\n",
    "\n",
    "\n",
    "pc1_testbin_loc = np.round((B-1)*(Ptest[:,0].astype(float)-range_PC1[0])/(range_PC1[1]-range_PC1[0])).astype('int32')\n",
    "pc2_testbin_loc = np.round((B-1)*(Ptest[:,1].astype(float)-range_PC2[0])/(range_PC2[1]-range_PC2[0])).astype('int32')\n",
    "\n",
    "Histogram_Label = np.zeros([10,Xtest.shape[0]]).astype('int32')\n",
    "Histogram_denominator = np.zeros(Xtest.shape[0]).astype('int32')\n",
    "for i in range(10):\n",
    "    Histogram_Label[i,:] = Hlabel[i,pc1_testbin_loc,pc2_testbin_loc]\n",
    "    Histogram_denominator += Histogram_Label[i,:]\n",
    "    \n",
    "Histogram_classifier = np.zeros([10,Xtest.shape[0]])\n",
    "for i in range(10):\n",
    "    Histogram_classifier[i,:] = Histogram_Label[i,:]/Histogram_denominator\n",
    "    Histogram_classifier[i,np.argwhere(np.isnan(Histogram_classifier[i,:]))] = 0\n",
    "\n",
    "Digits = [x for x in range(10)]\n",
    "DH = np.zeros(Xtest.shape[0]).astype('int32')\n",
    "PH = np.zeros(Xtest.shape[0])\n",
    "for j in range(Xtest.shape[0]):\n",
    "    DH[j] = Digits[np.argmax(Histogram_classifier[:,j])]\n",
    "    PH[j] = np.max(Histogram_classifier[:,j])\n",
    "    \n",
    "\n",
    "\n",
    "Bayesian_Label = np.zeros([10,Xtest.shape[0]])\n",
    "Bayesian_denominator = np.zeros(Xtest.shape[0])\n",
    "for i in range(10):\n",
    "    Bayesian_Label[i,:] = np.array([Gauss_2d_pdf(x,Mulabel[i],Covlabel[i]) for x in Ptest])\n",
    "    Bayesian_denominator += Bayesian_Label[i,:]\n",
    "    \n",
    "Bayesian_classifier = np.zeros([10,Xtest.shape[0]])\n",
    "for i in range(10):\n",
    "    Bayesian_classifier[i,:] = Bayesian_Label[i,:]/Bayesian_denominator\n",
    "    Bayesian_classifier[i,np.argwhere(np.isnan(Bayesian_classifier[i,:]))] = 0\n",
    "\n",
    "Digits = [x for x in range(10)]\n",
    "DB = np.zeros(Xtest.shape[0]).astype('int32')\n",
    "PB = np.zeros(Xtest.shape[0])\n",
    "for j in range(Xtest.shape[0]):\n",
    "    DB[j] = Digits[np.argmax(Bayesian_classifier[:,j])]\n",
    "    PB[j] = np.max(Bayesian_classifier[:,j])\n",
    "\n",
    "TestAccurancy_H = 0.\n",
    "TestAccurancy_B = 0.\n",
    "for i in range(Xtest.shape[0]):\n",
    "    TestAccurancy_H += np.sum(Ytest[i] == DH[i])/Xtest.shape[0]\n",
    "    TestAccurancy_B += np.sum(Ytest[i] == DB[i])/Xtest.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5594999999999547\n",
      "0.5259999999999584\n"
     ]
    }
   ],
   "source": [
    "print(TestAccurancy_H)\n",
    "print(TestAccurancy_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Try neural network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import tensorflow.keras.utils as utils\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = Xtrain/255\n",
    "X_test = Xtest/255\n",
    "y_train = utils.to_categorical(Ytrain)\n",
    "y_test = utils.to_categorical(Ytest)\n",
    "num_pixels = X_train.shape[1]\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_conncected_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels,kernel_initializer='normal',activation='tanh'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal',activation='softmax'))\n",
    "    model.compile(loss='mean_squared_error',optimizer='sgd',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = fully_conncected_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/159\n",
      " - 5s - loss: 0.0209 - acc: 0.8598 - val_loss: 0.0213 - val_acc: 0.8559\n",
      "Epoch 2/159\n",
      " - 4s - loss: 0.0209 - acc: 0.8598 - val_loss: 0.0213 - val_acc: 0.8556\n",
      "Epoch 3/159\n",
      " - 5s - loss: 0.0209 - acc: 0.8603 - val_loss: 0.0213 - val_acc: 0.8561\n",
      "Epoch 4/159\n",
      " - 4s - loss: 0.0208 - acc: 0.8602 - val_loss: 0.0213 - val_acc: 0.8555\n",
      "Epoch 5/159\n",
      " - 4s - loss: 0.0208 - acc: 0.8604 - val_loss: 0.0213 - val_acc: 0.8561\n",
      "Epoch 6/159\n",
      " - 4s - loss: 0.0208 - acc: 0.8606 - val_loss: 0.0213 - val_acc: 0.8561\n",
      "Epoch 7/159\n",
      " - 4s - loss: 0.0208 - acc: 0.8606 - val_loss: 0.0213 - val_acc: 0.8567\n",
      "Epoch 8/159\n",
      " - 5s - loss: 0.0208 - acc: 0.8607 - val_loss: 0.0212 - val_acc: 0.8565\n",
      "Epoch 9/159\n",
      " - 4s - loss: 0.0208 - acc: 0.8607 - val_loss: 0.0212 - val_acc: 0.8568\n",
      "Epoch 10/159\n",
      " - 5s - loss: 0.0208 - acc: 0.8610 - val_loss: 0.0212 - val_acc: 0.8566\n",
      "Epoch 11/159\n",
      " - 5s - loss: 0.0207 - acc: 0.8611 - val_loss: 0.0212 - val_acc: 0.8559\n",
      "Epoch 12/159\n",
      " - 5s - loss: 0.0207 - acc: 0.8608 - val_loss: 0.0212 - val_acc: 0.8570\n",
      "Epoch 13/159\n",
      " - 4s - loss: 0.0207 - acc: 0.8612 - val_loss: 0.0212 - val_acc: 0.8577\n",
      "Epoch 14/159\n",
      " - 4s - loss: 0.0207 - acc: 0.8615 - val_loss: 0.0212 - val_acc: 0.8562\n",
      "Epoch 15/159\n",
      " - 4s - loss: 0.0207 - acc: 0.8615 - val_loss: 0.0212 - val_acc: 0.8568\n",
      "Epoch 16/159\n",
      " - 5s - loss: 0.0207 - acc: 0.8613 - val_loss: 0.0212 - val_acc: 0.8569\n",
      "Epoch 17/159\n",
      " - 4s - loss: 0.0207 - acc: 0.8616 - val_loss: 0.0211 - val_acc: 0.8569\n",
      "Epoch 18/159\n",
      " - 3s - loss: 0.0207 - acc: 0.8616 - val_loss: 0.0211 - val_acc: 0.8583\n",
      "Epoch 19/159\n",
      " - 4s - loss: 0.0206 - acc: 0.8618 - val_loss: 0.0211 - val_acc: 0.8571\n",
      "Epoch 20/159\n",
      " - 4s - loss: 0.0206 - acc: 0.8619 - val_loss: 0.0211 - val_acc: 0.8569\n",
      "Epoch 21/159\n",
      " - 5s - loss: 0.0206 - acc: 0.8623 - val_loss: 0.0211 - val_acc: 0.8566\n",
      "Epoch 22/159\n",
      " - 4s - loss: 0.0206 - acc: 0.8622 - val_loss: 0.0211 - val_acc: 0.8585\n",
      "Epoch 23/159\n",
      " - 5s - loss: 0.0206 - acc: 0.8623 - val_loss: 0.0211 - val_acc: 0.8566\n",
      "Epoch 24/159\n",
      " - 4s - loss: 0.0206 - acc: 0.8623 - val_loss: 0.0211 - val_acc: 0.8579\n",
      "Epoch 25/159\n",
      " - 5s - loss: 0.0206 - acc: 0.8625 - val_loss: 0.0211 - val_acc: 0.8575\n",
      "Epoch 26/159\n",
      " - 5s - loss: 0.0206 - acc: 0.8626 - val_loss: 0.0211 - val_acc: 0.8572\n",
      "Epoch 27/159\n",
      " - 5s - loss: 0.0205 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8590\n",
      "Epoch 28/159\n",
      " - 4s - loss: 0.0205 - acc: 0.8627 - val_loss: 0.0211 - val_acc: 0.8581\n",
      "Epoch 29/159\n",
      " - 5s - loss: 0.0205 - acc: 0.8623 - val_loss: 0.0210 - val_acc: 0.8590\n",
      "Epoch 30/159\n",
      " - 5s - loss: 0.0205 - acc: 0.8626 - val_loss: 0.0210 - val_acc: 0.8574\n",
      "Epoch 31/159\n",
      " - 5s - loss: 0.0205 - acc: 0.8630 - val_loss: 0.0210 - val_acc: 0.8587\n",
      "Epoch 32/159\n",
      " - 5s - loss: 0.0205 - acc: 0.8632 - val_loss: 0.0210 - val_acc: 0.8581\n",
      "Epoch 33/159\n",
      " - 5s - loss: 0.0205 - acc: 0.8633 - val_loss: 0.0210 - val_acc: 0.8573\n",
      "Epoch 34/159\n",
      " - 4s - loss: 0.0205 - acc: 0.8632 - val_loss: 0.0210 - val_acc: 0.8576\n",
      "Epoch 35/159\n",
      " - 5s - loss: 0.0204 - acc: 0.8631 - val_loss: 0.0210 - val_acc: 0.8576\n",
      "Epoch 36/159\n",
      " - 4s - loss: 0.0204 - acc: 0.8635 - val_loss: 0.0210 - val_acc: 0.8569\n",
      "Epoch 37/159\n",
      " - 5s - loss: 0.0204 - acc: 0.8637 - val_loss: 0.0209 - val_acc: 0.8595\n",
      "Epoch 38/159\n",
      " - 5s - loss: 0.0204 - acc: 0.8635 - val_loss: 0.0209 - val_acc: 0.8578\n",
      "Epoch 39/159\n",
      " - 5s - loss: 0.0204 - acc: 0.8638 - val_loss: 0.0209 - val_acc: 0.8590\n",
      "Epoch 40/159\n",
      " - 4s - loss: 0.0204 - acc: 0.8639 - val_loss: 0.0209 - val_acc: 0.8572\n",
      "Epoch 41/159\n",
      " - 5s - loss: 0.0204 - acc: 0.8642 - val_loss: 0.0209 - val_acc: 0.8576\n",
      "Epoch 42/159\n",
      " - 4s - loss: 0.0204 - acc: 0.8644 - val_loss: 0.0209 - val_acc: 0.8578\n",
      "Epoch 43/159\n",
      " - 4s - loss: 0.0204 - acc: 0.8641 - val_loss: 0.0209 - val_acc: 0.8596\n",
      "Epoch 44/159\n",
      " - 4s - loss: 0.0203 - acc: 0.8644 - val_loss: 0.0209 - val_acc: 0.8599\n",
      "Epoch 45/159\n",
      " - 5s - loss: 0.0203 - acc: 0.8642 - val_loss: 0.0209 - val_acc: 0.8591\n",
      "Epoch 46/159\n",
      " - 5s - loss: 0.0203 - acc: 0.8642 - val_loss: 0.0209 - val_acc: 0.8582\n",
      "Epoch 47/159\n",
      " - 5s - loss: 0.0203 - acc: 0.8645 - val_loss: 0.0209 - val_acc: 0.8573\n",
      "Epoch 48/159\n",
      " - 5s - loss: 0.0203 - acc: 0.8646 - val_loss: 0.0208 - val_acc: 0.8582\n",
      "Epoch 49/159\n",
      " - 5s - loss: 0.0203 - acc: 0.8645 - val_loss: 0.0209 - val_acc: 0.8579\n",
      "Epoch 50/159\n",
      " - 5s - loss: 0.0203 - acc: 0.8649 - val_loss: 0.0208 - val_acc: 0.8588\n",
      "Epoch 51/159\n",
      " - 4s - loss: 0.0203 - acc: 0.8645 - val_loss: 0.0208 - val_acc: 0.8590\n",
      "Epoch 52/159\n",
      " - 5s - loss: 0.0202 - acc: 0.8648 - val_loss: 0.0209 - val_acc: 0.8593\n",
      "Epoch 53/159\n",
      " - 5s - loss: 0.0202 - acc: 0.8646 - val_loss: 0.0208 - val_acc: 0.8584\n",
      "Epoch 54/159\n",
      " - 5s - loss: 0.0202 - acc: 0.8651 - val_loss: 0.0208 - val_acc: 0.8608\n",
      "Epoch 55/159\n",
      " - 5s - loss: 0.0202 - acc: 0.8651 - val_loss: 0.0208 - val_acc: 0.8597\n",
      "Epoch 56/159\n",
      " - 4s - loss: 0.0202 - acc: 0.8652 - val_loss: 0.0208 - val_acc: 0.8592\n",
      "Epoch 57/159\n",
      " - 5s - loss: 0.0202 - acc: 0.8652 - val_loss: 0.0208 - val_acc: 0.8598\n",
      "Epoch 58/159\n",
      " - 5s - loss: 0.0202 - acc: 0.8653 - val_loss: 0.0208 - val_acc: 0.8593\n",
      "Epoch 59/159\n",
      " - 4s - loss: 0.0202 - acc: 0.8653 - val_loss: 0.0207 - val_acc: 0.8585\n",
      "Epoch 60/159\n",
      " - 5s - loss: 0.0202 - acc: 0.8659 - val_loss: 0.0207 - val_acc: 0.8584\n",
      "Epoch 61/159\n",
      " - 4s - loss: 0.0202 - acc: 0.8656 - val_loss: 0.0207 - val_acc: 0.8599\n",
      "Epoch 62/159\n",
      " - 4s - loss: 0.0201 - acc: 0.8651 - val_loss: 0.0208 - val_acc: 0.8592\n",
      "Epoch 63/159\n",
      " - 5s - loss: 0.0201 - acc: 0.8656 - val_loss: 0.0207 - val_acc: 0.8602\n",
      "Epoch 64/159\n",
      " - 5s - loss: 0.0201 - acc: 0.8657 - val_loss: 0.0207 - val_acc: 0.8604\n",
      "Epoch 65/159\n",
      " - 5s - loss: 0.0201 - acc: 0.8658 - val_loss: 0.0207 - val_acc: 0.8600\n",
      "Epoch 66/159\n",
      " - 5s - loss: 0.0201 - acc: 0.8657 - val_loss: 0.0207 - val_acc: 0.8588\n",
      "Epoch 67/159\n",
      " - 4s - loss: 0.0201 - acc: 0.8662 - val_loss: 0.0207 - val_acc: 0.8590\n",
      "Epoch 68/159\n",
      " - 4s - loss: 0.0201 - acc: 0.8659 - val_loss: 0.0207 - val_acc: 0.8596\n",
      "Epoch 69/159\n",
      " - 5s - loss: 0.0201 - acc: 0.8660 - val_loss: 0.0207 - val_acc: 0.8602\n",
      "Epoch 70/159\n",
      " - 5s - loss: 0.0201 - acc: 0.8657 - val_loss: 0.0207 - val_acc: 0.8606\n",
      "Epoch 71/159\n",
      " - 4s - loss: 0.0201 - acc: 0.8662 - val_loss: 0.0207 - val_acc: 0.8601\n",
      "Epoch 72/159\n",
      " - 5s - loss: 0.0200 - acc: 0.8663 - val_loss: 0.0207 - val_acc: 0.8609\n",
      "Epoch 73/159\n",
      " - 5s - loss: 0.0200 - acc: 0.8660 - val_loss: 0.0206 - val_acc: 0.8607\n",
      "Epoch 74/159\n",
      " - 4s - loss: 0.0200 - acc: 0.8664 - val_loss: 0.0206 - val_acc: 0.8602\n",
      "Epoch 75/159\n",
      " - 4s - loss: 0.0200 - acc: 0.8666 - val_loss: 0.0206 - val_acc: 0.8608\n",
      "Epoch 76/159\n",
      " - 4s - loss: 0.0200 - acc: 0.8669 - val_loss: 0.0206 - val_acc: 0.8606\n",
      "Epoch 77/159\n",
      " - 5s - loss: 0.0200 - acc: 0.8664 - val_loss: 0.0206 - val_acc: 0.8605\n",
      "Epoch 78/159\n",
      " - 5s - loss: 0.0200 - acc: 0.8666 - val_loss: 0.0206 - val_acc: 0.8600\n",
      "Epoch 79/159\n",
      " - 5s - loss: 0.0200 - acc: 0.8671 - val_loss: 0.0206 - val_acc: 0.8610\n",
      "Epoch 80/159\n",
      " - 5s - loss: 0.0200 - acc: 0.8668 - val_loss: 0.0206 - val_acc: 0.8612\n",
      "Epoch 81/159\n",
      " - 4s - loss: 0.0200 - acc: 0.8667 - val_loss: 0.0206 - val_acc: 0.8602\n",
      "Epoch 82/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8668 - val_loss: 0.0206 - val_acc: 0.8611\n",
      "Epoch 83/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8669 - val_loss: 0.0206 - val_acc: 0.8613\n",
      "Epoch 84/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8669 - val_loss: 0.0206 - val_acc: 0.8607\n",
      "Epoch 85/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8670 - val_loss: 0.0205 - val_acc: 0.8615\n",
      "Epoch 86/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8674 - val_loss: 0.0206 - val_acc: 0.8618\n",
      "Epoch 87/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8672 - val_loss: 0.0205 - val_acc: 0.8611\n",
      "Epoch 88/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8671 - val_loss: 0.0205 - val_acc: 0.8597\n",
      "Epoch 89/159\n",
      " - 4s - loss: 0.0199 - acc: 0.8668 - val_loss: 0.0205 - val_acc: 0.8603\n",
      "Epoch 90/159\n",
      " - 4s - loss: 0.0199 - acc: 0.8676 - val_loss: 0.0205 - val_acc: 0.8611\n",
      "Epoch 91/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8675 - val_loss: 0.0205 - val_acc: 0.8605\n",
      "Epoch 92/159\n",
      " - 5s - loss: 0.0199 - acc: 0.8675 - val_loss: 0.0205 - val_acc: 0.8604\n",
      "Epoch 93/159\n",
      " - 4s - loss: 0.0198 - acc: 0.8675 - val_loss: 0.0205 - val_acc: 0.8617\n",
      "Epoch 94/159\n",
      " - 4s - loss: 0.0198 - acc: 0.8673 - val_loss: 0.0205 - val_acc: 0.8611\n",
      "Epoch 95/159\n",
      " - 5s - loss: 0.0198 - acc: 0.8673 - val_loss: 0.0205 - val_acc: 0.8615\n",
      "Epoch 96/159\n",
      " - 5s - loss: 0.0198 - acc: 0.8677 - val_loss: 0.0205 - val_acc: 0.8609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/159\n",
      " - 5s - loss: 0.0198 - acc: 0.8674 - val_loss: 0.0205 - val_acc: 0.8613\n",
      "Epoch 98/159\n",
      " - 4s - loss: 0.0198 - acc: 0.8679 - val_loss: 0.0205 - val_acc: 0.8616\n",
      "Epoch 99/159\n",
      " - 5s - loss: 0.0198 - acc: 0.8680 - val_loss: 0.0204 - val_acc: 0.8611\n",
      "Epoch 100/159\n",
      " - 5s - loss: 0.0198 - acc: 0.8679 - val_loss: 0.0204 - val_acc: 0.8613\n",
      "Epoch 101/159\n",
      " - 5s - loss: 0.0198 - acc: 0.8680 - val_loss: 0.0204 - val_acc: 0.8605\n",
      "Epoch 102/159\n",
      " - 5s - loss: 0.0198 - acc: 0.8681 - val_loss: 0.0204 - val_acc: 0.8611\n",
      "Epoch 103/159\n",
      " - 5s - loss: 0.0197 - acc: 0.8683 - val_loss: 0.0204 - val_acc: 0.8611\n",
      "Epoch 104/159\n",
      " - 4s - loss: 0.0197 - acc: 0.8682 - val_loss: 0.0204 - val_acc: 0.8619\n",
      "Epoch 105/159\n",
      " - 4s - loss: 0.0197 - acc: 0.8684 - val_loss: 0.0204 - val_acc: 0.8613\n",
      "Epoch 106/159\n",
      " - 5s - loss: 0.0197 - acc: 0.8683 - val_loss: 0.0204 - val_acc: 0.8611\n",
      "Epoch 107/159\n",
      " - 5s - loss: 0.0197 - acc: 0.8680 - val_loss: 0.0204 - val_acc: 0.8618\n",
      "Epoch 108/159\n",
      " - 4s - loss: 0.0197 - acc: 0.8684 - val_loss: 0.0204 - val_acc: 0.8615\n",
      "Epoch 109/159\n",
      " - 4s - loss: 0.0197 - acc: 0.8683 - val_loss: 0.0204 - val_acc: 0.8619\n",
      "Epoch 110/159\n",
      " - 5s - loss: 0.0197 - acc: 0.8683 - val_loss: 0.0204 - val_acc: 0.8615\n",
      "Epoch 111/159\n",
      " - 5s - loss: 0.0197 - acc: 0.8686 - val_loss: 0.0204 - val_acc: 0.8621\n",
      "Epoch 112/159\n",
      " - 5s - loss: 0.0197 - acc: 0.8686 - val_loss: 0.0203 - val_acc: 0.8619\n",
      "Epoch 113/159\n",
      " - 4s - loss: 0.0197 - acc: 0.8684 - val_loss: 0.0203 - val_acc: 0.8611\n",
      "Epoch 114/159\n",
      " - 4s - loss: 0.0197 - acc: 0.8690 - val_loss: 0.0204 - val_acc: 0.8622\n",
      "Epoch 115/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8691 - val_loss: 0.0203 - val_acc: 0.8612\n",
      "Epoch 116/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8689 - val_loss: 0.0203 - val_acc: 0.8616\n",
      "Epoch 117/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8689 - val_loss: 0.0203 - val_acc: 0.8617\n",
      "Epoch 118/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8690 - val_loss: 0.0203 - val_acc: 0.8617\n",
      "Epoch 119/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8692 - val_loss: 0.0203 - val_acc: 0.8617\n",
      "Epoch 120/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8691 - val_loss: 0.0203 - val_acc: 0.8622\n",
      "Epoch 121/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8693 - val_loss: 0.0203 - val_acc: 0.8619\n",
      "Epoch 122/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8689 - val_loss: 0.0203 - val_acc: 0.8617\n",
      "Epoch 123/159\n",
      " - 5s - loss: 0.0196 - acc: 0.8696 - val_loss: 0.0203 - val_acc: 0.8612\n",
      "Epoch 124/159\n",
      " - 5s - loss: 0.0196 - acc: 0.8695 - val_loss: 0.0203 - val_acc: 0.8618\n",
      "Epoch 125/159\n",
      " - 4s - loss: 0.0196 - acc: 0.8693 - val_loss: 0.0203 - val_acc: 0.8614\n",
      "Epoch 126/159\n",
      " - 5s - loss: 0.0196 - acc: 0.8697 - val_loss: 0.0203 - val_acc: 0.8619\n",
      "Epoch 127/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8695 - val_loss: 0.0202 - val_acc: 0.8619\n",
      "Epoch 128/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8694 - val_loss: 0.0202 - val_acc: 0.8618\n",
      "Epoch 129/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8699 - val_loss: 0.0202 - val_acc: 0.8624\n",
      "Epoch 130/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8698 - val_loss: 0.0202 - val_acc: 0.8623\n",
      "Epoch 131/159\n",
      " - 4s - loss: 0.0195 - acc: 0.8695 - val_loss: 0.0202 - val_acc: 0.8614\n",
      "Epoch 132/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8699 - val_loss: 0.0202 - val_acc: 0.8624\n",
      "Epoch 133/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8697 - val_loss: 0.0202 - val_acc: 0.8622\n",
      "Epoch 134/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8699 - val_loss: 0.0202 - val_acc: 0.8622\n",
      "Epoch 135/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8700 - val_loss: 0.0202 - val_acc: 0.8620\n",
      "Epoch 136/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8697 - val_loss: 0.0202 - val_acc: 0.8622\n",
      "Epoch 137/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8699 - val_loss: 0.0202 - val_acc: 0.8620\n",
      "Epoch 138/159\n",
      " - 5s - loss: 0.0195 - acc: 0.8701 - val_loss: 0.0202 - val_acc: 0.8621\n",
      "Epoch 139/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8702 - val_loss: 0.0202 - val_acc: 0.8621\n",
      "Epoch 140/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8702 - val_loss: 0.0202 - val_acc: 0.8621\n",
      "Epoch 141/159\n",
      " - 4s - loss: 0.0194 - acc: 0.8705 - val_loss: 0.0202 - val_acc: 0.8627\n",
      "Epoch 142/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8702 - val_loss: 0.0202 - val_acc: 0.8626\n",
      "Epoch 143/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8709 - val_loss: 0.0202 - val_acc: 0.8630\n",
      "Epoch 144/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8705 - val_loss: 0.0202 - val_acc: 0.8624\n",
      "Epoch 145/159\n",
      " - 4s - loss: 0.0194 - acc: 0.8708 - val_loss: 0.0201 - val_acc: 0.8629\n",
      "Epoch 146/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8706 - val_loss: 0.0201 - val_acc: 0.8626\n",
      "Epoch 147/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8709 - val_loss: 0.0201 - val_acc: 0.8623\n",
      "Epoch 148/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8709 - val_loss: 0.0201 - val_acc: 0.8623\n",
      "Epoch 149/159\n",
      " - 4s - loss: 0.0194 - acc: 0.8707 - val_loss: 0.0201 - val_acc: 0.8633\n",
      "Epoch 150/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8708 - val_loss: 0.0201 - val_acc: 0.8632\n",
      "Epoch 151/159\n",
      " - 5s - loss: 0.0194 - acc: 0.8706 - val_loss: 0.0201 - val_acc: 0.8632\n",
      "Epoch 152/159\n",
      " - 5s - loss: 0.0193 - acc: 0.8710 - val_loss: 0.0201 - val_acc: 0.8628\n",
      "Epoch 153/159\n",
      " - 5s - loss: 0.0193 - acc: 0.8710 - val_loss: 0.0201 - val_acc: 0.8626\n",
      "Epoch 154/159\n",
      " - 4s - loss: 0.0193 - acc: 0.8711 - val_loss: 0.0201 - val_acc: 0.8619\n",
      "Epoch 155/159\n",
      " - 4s - loss: 0.0193 - acc: 0.8710 - val_loss: 0.0201 - val_acc: 0.8637\n",
      "Epoch 156/159\n",
      " - 5s - loss: 0.0193 - acc: 0.8714 - val_loss: 0.0201 - val_acc: 0.8628\n",
      "Epoch 157/159\n",
      " - 5s - loss: 0.0193 - acc: 0.8712 - val_loss: 0.0201 - val_acc: 0.8625\n",
      "Epoch 158/159\n",
      " - 5s - loss: 0.0193 - acc: 0.8712 - val_loss: 0.0201 - val_acc: 0.8625\n",
      "Epoch 159/159\n",
      " - 5s - loss: 0.0193 - acc: 0.8713 - val_loss: 0.0201 - val_acc: 0.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2dc8f98>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=159,batch_size=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 86.31%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test,y_test,verbose=2)\n",
    "print(\"Validation Accuracy: %.2f%%\"%(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02006090875789523, 0.8631]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
